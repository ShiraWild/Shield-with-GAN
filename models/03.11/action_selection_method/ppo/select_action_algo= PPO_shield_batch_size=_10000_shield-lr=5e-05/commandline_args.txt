select_action_algo: PPO
env: CartPoleWithCost-v0
max_ep_len: 200
max_training_timesteps: 1000000
render: False
cpu: 4
seed: 0
log_freq: 500
save_model_freq: 5000
base_path: models/03.11/action_selection_method/ppo
record_trajectory_length: 200
save_buffer_pickle: False
ppo_K_epochs: 80
ppo_eps_clip: 0.2
ppo_gamma: 0.99
ppo_lr_actor: 0.0003
ppo_lr_critic: 0.001
shield_K_epochs: 30
shield_discount_factor_cost: 0.9
shield_unsafe_tresh: 0.5
shield_update_episode: 10.0
shield_batch_size: 10000
shield_buffer_size: 1000000
shield_lr: 5e-05
shield_minimum_buffer_samples: 40000
shield_sub_batch_size: 500
shield_convergence_threshold: 0.01
shield_convergence_episodes_interval: 100
safe_limit_x: 0.1
safe_limit_theta: 0.01
